"""
Gradioç»Ÿä¸€å·¥ä½œå° - é›†æˆæ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€è§†é¢‘å­—å¹•ã€æç¤ºè¯åŠ©ç†
"""

import gradio as gr
import logging
import os
from pathlib import Path
from typing import List, Optional, Tuple, Any
import json

# å¯¼å…¥æ¨¡å—
from modules.stable_diffusion_module import StableDiffusionModule
from modules.blip_video_module import BLIPVideoModule
from modules.nano_gpt_module import NanoGPTModule
from configs.settings import OUTPUT_DIRS, DEFAULT_PARAMS, SECURITY_CONFIG

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å…¨å±€æ¨¡å—å®ä¾‹
sd_module = None
blip_module = None
gpt_module = None


def initialize_modules():
    """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—"""
    global sd_module, blip_module, gpt_module
    
    try:
        logger.info("Initializing modules...")
        
        # åˆå§‹åŒ–Stable Diffusionæ¨¡å—
        sd_module = StableDiffusionModule()
        logger.info("âœ… Stable Diffusion module initialized")
        
        # åˆå§‹åŒ–BLIP Videoæ¨¡å—
        blip_module = BLIPVideoModule()
        logger.info("âœ… BLIP Video module initialized")
        
        # åˆå§‹åŒ–Nano GPTæ¨¡å—
        gpt_module = NanoGPTModule()
        logger.info("âœ… Nano GPT module initialized")
        
        logger.info("ğŸ‰ All modules initialized successfully!")
        
    except Exception as e:
        logger.error(f"Failed to initialize modules: {e}")
        raise


def validate_prompt(prompt: str) -> bool:
    """éªŒè¯æç¤ºè¯å®‰å…¨æ€§"""
    if not prompt or len(prompt.strip()) == 0:
        return False
    
    if len(prompt) > SECURITY_CONFIG["max_prompt_length"]:
        return False
    
    prompt_lower = prompt.lower()
    for keyword in SECURITY_CONFIG["blocked_keywords"]:
        if keyword in prompt_lower:
            return False
    
    return True


def text2img_interface(
    prompt: str,
    negative_prompt: str,
    width: int,
    height: int,
    num_inference_steps: int,
    guidance_scale: float,
    num_images: int,
    seed: Optional[int],
    use_sdxl: bool
) -> List[str]:
    """æ–‡ç”Ÿå›¾æ¥å£"""
    try:
        if not validate_prompt(prompt):
            return [None], "âŒ æç¤ºè¯ä¸ç¬¦åˆå®‰å…¨è¦æ±‚"
        
        if sd_module is None:
            return [None], "âŒ Stable Diffusionæ¨¡å—æœªåˆå§‹åŒ–"
        
        # ç”Ÿæˆå›¾ç‰‡
        images = sd_module.text2img(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            num_images_per_prompt=num_images,
            seed=seed,
            use_sdxl=use_sdxl
        )
        
        # è¿”å›å›¾ç‰‡è·¯å¾„
        image_paths = []
        for img in images:
            # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
            temp_path = OUTPUT_DIRS["images"] / f"temp_{len(image_paths)}.png"
            img.save(temp_path)
            image_paths.append(str(temp_path))
        
        return image_paths, f"âœ… æˆåŠŸç”Ÿæˆ {len(images)} å¼ å›¾ç‰‡"
        
    except Exception as e:
        logger.error(f"Text2Img failed: {e}")
        return [None], f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"


def img2img_interface(
    prompt: str,
    negative_prompt: str,
    image: Any,
    strength: float,
    num_inference_steps: int,
    guidance_scale: float,
    num_images: int,
    seed: Optional[int],
    use_sdxl: bool
) -> List[str]:
    """å›¾ç”Ÿå›¾æ¥å£"""
    try:
        if not validate_prompt(prompt):
            return [None], "âŒ æç¤ºè¯ä¸ç¬¦åˆå®‰å…¨è¦æ±‚"
        
        if image is None:
            return [None], "âŒ è¯·ä¸Šä¼ è¾“å…¥å›¾ç‰‡"
        
        if sd_module is None:
            return [None], "âŒ Stable Diffusionæ¨¡å—æœªåˆå§‹åŒ–"
        
        # ç”Ÿæˆå›¾ç‰‡
        images = sd_module.img2img(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=image,
            strength=strength,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            num_images_per_prompt=num_images,
            seed=seed,
            use_sdxl=use_sdxl
        )
        
        # è¿”å›å›¾ç‰‡è·¯å¾„
        image_paths = []
        for img in images:
            temp_path = OUTPUT_DIRS["images"] / f"temp_{len(image_paths)}.png"
            img.save(temp_path)
            image_paths.append(str(temp_path))
        
        return image_paths, f"âœ… æˆåŠŸç”Ÿæˆ {len(images)} å¼ å›¾ç‰‡"
        
    except Exception as e:
        logger.error(f"Img2Img failed: {e}")
        return [None], f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"


def video_caption_interface(
    video: Any,
    fps: float,
    max_frames: int,
    max_length: int,
    export_srt: bool,
    export_vtt: bool
) -> Tuple[str, str, str]:
    """è§†é¢‘å­—å¹•æ¥å£"""
    try:
        if video is None:
            return None, None, "âŒ è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶"
        
        if blip_module is None:
            return None, None, "âŒ BLIP Videoæ¨¡å—æœªåˆå§‹åŒ–"
        
        # å¤„ç†è§†é¢‘
        results = blip_module.process_video_with_captions(
            video_path=video,
            fps=fps,
            max_frames=max_frames,
            export_formats=(["srt"] if export_srt else []) + (["vtt"] if export_vtt else [])
        )
        
        # ç”Ÿæˆå­—å¹•æ–‡æœ¬
        captions_text = ""
        for caption_data in results["captions"]:
            captions_text += f"[{caption_data['timestamp']:.1f}s] {caption_data['caption']}\n"
        
        # è¿”å›æ–‡ä»¶è·¯å¾„
        srt_file = None
        vtt_file = None
        
        for file_path in results["exported_files"]:
            if file_path.endswith('.srt'):
                srt_file = file_path
            elif file_path.endswith('.vtt'):
                vtt_file = file_path
        
        return srt_file, vtt_file, f"âœ… æˆåŠŸç”Ÿæˆ {len(results['captions'])} ä¸ªå­—å¹•"
        
    except Exception as e:
        logger.error(f"Video caption failed: {e}")
        return None, None, f"âŒ å¤„ç†å¤±è´¥: {str(e)}"


def prompt_assistant_interface(
    base_prompt: str,
    operation: str,
    style: str,
    max_length: int,
    temperature: float
) -> Tuple[str, str, str]:
    """æç¤ºè¯åŠ©ç†æ¥å£"""
    try:
        if not base_prompt or len(base_prompt.strip()) == 0:
            return "", "", "âŒ è¯·è¾“å…¥åŸºç¡€æç¤ºè¯"
        
        if gpt_module is None:
            return "", "", "âŒ Nano GPTæ¨¡å—æœªåˆå§‹åŒ–"
        
        # æ‰§è¡Œæ“ä½œ
        if operation == "expand":
            results = gpt_module.expand_prompt(
                base_prompt, 
                style=style, 
                max_length=max_length, 
                temperature=temperature
            )
        elif operation == "optimize":
            results = gpt_module.optimize_prompt(
                base_prompt, 
                target_style=style, 
                max_length=max_length
            )
        elif operation == "negative":
            results = gpt_module.generate_negative_prompt(base_prompt)
        else:
            results = [base_prompt]
        
        # åˆ†ææç¤ºè¯è´¨é‡
        analysis = gpt_module.analyze_prompt_quality(base_prompt)
        
        # æ ¼å¼åŒ–è¾“å‡º
        expanded_prompts = "\n\n".join([f"ç‰ˆæœ¬ {i+1}:\n{result}" for i, result in enumerate(results)])
        
        analysis_text = f"""
æç¤ºè¯åˆ†æ:
- é•¿åº¦: {analysis['length']} å­—ç¬¦
- è¯æ•°: {analysis['word_count']} ä¸ªè¯
- åŒ…å«é£æ ¼: {'âœ…' if analysis['has_style'] else 'âŒ'}
- åŒ…å«è´¨é‡: {'âœ…' if analysis['has_quality'] else 'âŒ'}
- åŒ…å«å…‰ç…§: {'âœ…' if analysis['has_lighting'] else 'âŒ'}
- åŒ…å«æ„å›¾: {'âœ…' if analysis['has_composition'] else 'âŒ'}

å»ºè®®:
{chr(10).join(f"- {suggestion}" for suggestion in analysis['suggestions'])}
"""
        
        return expanded_prompts, analysis_text, f"âœ… æˆåŠŸå¤„ç†æç¤ºè¯"
        
    except Exception as e:
        logger.error(f"Prompt assistant failed: {e}")
        return "", "", f"âŒ å¤„ç†å¤±è´¥: {str(e)}"


def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    # è‡ªå®šä¹‰CSS
    css = """
    .gradio-container {
        max-width: 1200px !important;
    }
    .tab-nav {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    }
    """
    
    with gr.Blocks(css=css, title="AIåˆ›ä½œå·¥ä½œå°") as app:
        gr.Markdown("""
        # ğŸ¨ AIåˆ›ä½œå·¥ä½œå°
        **é›†æˆæ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€è§†é¢‘å­—å¹•ã€æç¤ºè¯åŠ©ç†çš„ä¸€ä½“åŒ–å¹³å°**
        """)
        
        with gr.Tabs():
            # æ–‡ç”Ÿå›¾æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ¨ æ–‡ç”Ÿå›¾"):
                with gr.Row():
                    with gr.Column(scale=1):
                        text2img_prompt = gr.Textbox(
                            label="æç¤ºè¯",
                            placeholder="æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„å›¾ç‰‡...",
                            lines=3
                        )
                        text2img_negative = gr.Textbox(
                            label="è´Ÿé¢æç¤ºè¯",
                            placeholder="æè¿°ä¸æƒ³è¦çš„å†…å®¹...",
                            lines=2
                        )
                        
                        with gr.Row():
                            text2img_width = gr.Slider(256, 1024, 512, step=64, label="å®½åº¦")
                            text2img_height = gr.Slider(256, 1024, 512, step=64, label="é«˜åº¦")
                        
                        with gr.Row():
                            text2img_steps = gr.Slider(10, 50, 20, step=5, label="æ¨ç†æ­¥æ•°")
                            text2img_guidance = gr.Slider(1.0, 20.0, 7.5, step=0.5, label="å¼•å¯¼å¼ºåº¦")
                        
                        with gr.Row():
                            text2img_num = gr.Slider(1, 4, 1, step=1, label="ç”Ÿæˆæ•°é‡")
                            text2img_seed = gr.Number(label="ç§å­", precision=0)
                        
                        text2img_sdxl = gr.Checkbox(label="ä½¿ç”¨SDXLæ¨¡å‹", value=False)
                        
                        text2img_btn = gr.Button("ğŸ¨ ç”Ÿæˆå›¾ç‰‡", variant="primary")
                    
                    with gr.Column(scale=1):
                        text2img_output = gr.Gallery(label="ç”Ÿæˆçš„å›¾ç‰‡")
                        text2img_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
            
            # å›¾ç”Ÿå›¾æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ”„ å›¾ç”Ÿå›¾"):
                with gr.Row():
                    with gr.Column(scale=1):
                        img2img_prompt = gr.Textbox(
                            label="æç¤ºè¯",
                            placeholder="æè¿°ä½ æƒ³è¦çš„å˜æ¢æ•ˆæœ...",
                            lines=3
                        )
                        img2img_negative = gr.Textbox(
                            label="è´Ÿé¢æç¤ºè¯",
                            placeholder="æè¿°ä¸æƒ³è¦çš„å†…å®¹...",
                            lines=2
                        )
                        img2img_input = gr.Image(label="è¾“å…¥å›¾ç‰‡", type="pil")
                        
                        with gr.Row():
                            img2img_strength = gr.Slider(0.1, 1.0, 0.7, step=0.1, label="å˜æ¢å¼ºåº¦")
                            img2img_steps = gr.Slider(10, 50, 20, step=5, label="æ¨ç†æ­¥æ•°")
                        
                        with gr.Row():
                            img2img_guidance = gr.Slider(1.0, 20.0, 7.5, step=0.5, label="å¼•å¯¼å¼ºåº¦")
                            img2img_num = gr.Slider(1, 4, 1, step=1, label="ç”Ÿæˆæ•°é‡")
                        
                        with gr.Row():
                            img2img_seed = gr.Number(label="ç§å­", precision=0)
                            img2img_sdxl = gr.Checkbox(label="ä½¿ç”¨SDXLæ¨¡å‹", value=False)
                        
                        img2img_btn = gr.Button("ğŸ”„ ç”Ÿæˆå›¾ç‰‡", variant="primary")
                    
                    with gr.Column(scale=1):
                        img2img_output = gr.Gallery(label="ç”Ÿæˆçš„å›¾ç‰‡")
                        img2img_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
            
            # è§†é¢‘å­—å¹•æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ¬ è§†é¢‘å­—å¹•"):
                with gr.Row():
                    with gr.Column(scale=1):
                        video_input = gr.Video(label="è¾“å…¥è§†é¢‘")
                        
                        with gr.Row():
                            video_fps = gr.Slider(0.1, 2.0, 1.0, step=0.1, label="é‡‡æ ·å¸§ç‡")
                            video_max_frames = gr.Slider(10, 200, 50, step=10, label="æœ€å¤§å¸§æ•°")
                        
                        video_max_length = gr.Slider(20, 200, 100, step=10, label="å­—å¹•æœ€å¤§é•¿åº¦")
                        
                        with gr.Row():
                            video_export_srt = gr.Checkbox(label="å¯¼å‡ºSRT", value=True)
                            video_export_vtt = gr.Checkbox(label="å¯¼å‡ºVTT", value=True)
                        
                        video_btn = gr.Button("ğŸ¬ ç”Ÿæˆå­—å¹•", variant="primary")
                    
                    with gr.Column(scale=1):
                        video_srt_output = gr.File(label="SRTå­—å¹•æ–‡ä»¶")
                        video_vtt_output = gr.File(label="VTTå­—å¹•æ–‡ä»¶")
                        video_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
            
            # æç¤ºè¯åŠ©ç†æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ¤– æç¤ºè¯åŠ©ç†"):
                with gr.Row():
                    with gr.Column(scale=1):
                        prompt_base = gr.Textbox(
                            label="åŸºç¡€æç¤ºè¯",
                            placeholder="è¾“å…¥ä½ çš„åŸºç¡€æç¤ºè¯...",
                            lines=3
                        )
                        
                        with gr.Row():
                            prompt_operation = gr.Radio(
                                choices=["expand", "optimize", "negative"],
                                value="expand",
                                label="æ“ä½œç±»å‹"
                            )
                            prompt_style = gr.Dropdown(
                                choices=["detailed", "artistic", "photorealistic", "fantasy", "sci-fi", "anime", "vintage"],
                                value="detailed",
                                label="é£æ ¼"
                            )
                        
                        with gr.Row():
                            prompt_max_length = gr.Slider(50, 300, 150, step=10, label="æœ€å¤§é•¿åº¦")
                            prompt_temperature = gr.Slider(0.1, 1.5, 0.8, step=0.1, label="åˆ›é€ æ€§")
                        
                        prompt_btn = gr.Button("ğŸ¤– å¤„ç†æç¤ºè¯", variant="primary")
                    
                    with gr.Column(scale=1):
                        prompt_output = gr.Textbox(
                            label="å¤„ç†ç»“æœ",
                            lines=10,
                            interactive=False
                        )
                        prompt_analysis = gr.Textbox(
                            label="æç¤ºè¯åˆ†æ",
                            lines=8,
                            interactive=False
                        )
                        prompt_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
        
        # ç»‘å®šäº‹ä»¶
        text2img_btn.click(
            fn=text2img_interface,
            inputs=[
                text2img_prompt, text2img_negative, text2img_width, text2img_height,
                text2img_steps, text2img_guidance, text2img_num, text2img_seed, text2img_sdxl
            ],
            outputs=[text2img_output, text2img_status]
        )
        
        img2img_btn.click(
            fn=img2img_interface,
            inputs=[
                img2img_prompt, img2img_negative, img2img_input, img2img_strength,
                img2img_steps, img2img_guidance, img2img_num, img2img_seed, img2img_sdxl
            ],
            outputs=[img2img_output, img2img_status]
        )
        
        video_btn.click(
            fn=video_caption_interface,
            inputs=[
                video_input, video_fps, video_max_frames, video_max_length,
                video_export_srt, video_export_vtt
            ],
            outputs=[video_srt_output, video_vtt_output, video_status]
        )
        
        prompt_btn.click(
            fn=prompt_assistant_interface,
            inputs=[
                prompt_base, prompt_operation, prompt_style, prompt_max_length, prompt_temperature
            ],
            outputs=[prompt_output, prompt_analysis, prompt_status]
        )
    
    return app


def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆå§‹åŒ–æ¨¡å—
        initialize_modules()
        
        # åˆ›å»ºç•Œé¢
        app = create_interface()
        
        # å¯åŠ¨åº”ç”¨
        app.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=False,
            debug=True
        )
        
    except Exception as e:
        logger.error(f"Application failed to start: {e}")
        raise


if __name__ == "__main__":
    main()
