#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾ç”Ÿå›¾ä½¿ç”¨ç¤ºä¾‹
Image-to-Image Generation Example

ä½¿ç”¨æ–¹æ³•:
1. ç›´æ¥è¿è¡Œ: python img2img_example.py
2. æˆ–è€…å¯¼å…¥ä½¿ç”¨: from img2img_example import simple_img2img
"""

import os
from PIL import Image
from Laten_SD import StableDiffusionApp


def simple_img2img_example():
    """ç®€å•çš„å›¾ç”Ÿå›¾ç¤ºä¾‹"""
    print("ğŸ¨ ç®€å•å›¾ç”Ÿå›¾ç¤ºä¾‹")
    print("=" * 40)
    
    # åˆå§‹åŒ–åº”ç”¨
    app = StableDiffusionApp()
    
    # ç¤ºä¾‹1: ä½¿ç”¨ç°æœ‰å›¾ç‰‡
    print("\nğŸ“¸ ç¤ºä¾‹1: ä½¿ç”¨ç°æœ‰å›¾ç‰‡")
    
    # å¦‚æœä½ æœ‰ç°æœ‰å›¾ç‰‡ï¼Œå¯ä»¥è¿™æ ·ä½¿ç”¨:
    # image_path = "path/to/your/image.jpg"
    # if os.path.exists(image_path):
    #     result = app.generate_img2img(
    #         prompt="transform into anime style",
    #         image=image_path,
    #         strength=0.7,
    #         num_inference_steps=30
    #     )
    
    # ç¤ºä¾‹2: å…ˆç”ŸæˆåŸºç¡€å›¾ç‰‡ï¼Œå†è¿›è¡Œå›¾ç”Ÿå›¾
    print("\nğŸ­ ç¤ºä¾‹2: ç”ŸæˆåŸºç¡€å›¾ç‰‡åè¿›è¡Œå›¾ç”Ÿå›¾")
    
    # æ­¥éª¤1: ç”ŸæˆåŸºç¡€å›¾ç‰‡
    print("Step 1: ç”ŸæˆåŸºç¡€å›¾ç‰‡...")
    base_images = app.generate_text2img(
        prompt="a simple portrait of a person, neutral expression, clean background",
        negative_prompt="blurry, low quality, distorted",
        num_inference_steps=20,
        guidance_scale=7.5,
        num_images_per_prompt=1,
        seed=123
    )
    
    if not base_images:
        print("âŒ åŸºç¡€å›¾ç‰‡ç”Ÿæˆå¤±è´¥")
        return
    
    base_image = base_images[0]
    print("âœ… åŸºç¡€å›¾ç‰‡ç”ŸæˆæˆåŠŸ!")
    
    # æ­¥éª¤2: è¿›è¡Œå›¾ç”Ÿå›¾å˜æ¢
    print("\nStep 2: è¿›è¡Œå›¾ç”Ÿå›¾å˜æ¢...")
    
    # å˜æ¢1: èµ›åšæœ‹å…‹é£æ ¼
    print("ğŸ­ å˜æ¢1: èµ›åšæœ‹å…‹é£æ ¼")
    cyberpunk_result = app.generate_img2img(
        prompt="transform into cyberpunk style with neon lights and futuristic elements",
        image=base_image,
        negative_prompt="blurry, low quality, distorted, ugly",
        strength=0.7,  # å˜æ¢å¼ºåº¦ (0.0-1.0)
        guidance_scale=7.5,
        num_inference_steps=30,
        num_images_per_prompt=1,
        seed=456
    )
    
    if cyberpunk_result:
        print("âœ… èµ›åšæœ‹å…‹å˜æ¢å®Œæˆ!")
        app.display_images(cyberpunk_result, "Cyberpunk Style")
    
    # å˜æ¢2: å¤å…¸æ²¹ç”»é£æ ¼
    print("\nğŸ¨ å˜æ¢2: å¤å…¸æ²¹ç”»é£æ ¼")
    painting_result = app.generate_img2img(
        prompt="make it look like a classical oil painting with rich colors and brushstrokes",
        image=base_image,
        negative_prompt="blurry, low quality, distorted, ugly",
        strength=0.8,  # æ›´é«˜çš„å˜æ¢å¼ºåº¦
        guidance_scale=7.5,
        num_inference_steps=30,
        num_images_per_prompt=1,
        seed=789
    )
    
    if painting_result:
        print("âœ… å¤å…¸æ²¹ç”»å˜æ¢å®Œæˆ!")
        app.display_images(painting_result, "Classical Painting Style")


def custom_img2img(prompt: str, image_path: str, strength: float = 0.7):
    """è‡ªå®šä¹‰å›¾ç”Ÿå›¾å‡½æ•°"""
    print(f"ğŸ¨ è‡ªå®šä¹‰å›¾ç”Ÿå›¾: {prompt}")
    print("=" * 40)
    
    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_path):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return None
    
    # åˆå§‹åŒ–åº”ç”¨
    app = StableDiffusionApp()
    
    try:
        # è¿›è¡Œå›¾ç”Ÿå›¾
        result = app.generate_img2img(
            prompt=prompt,
            image=image_path,
            negative_prompt="blurry, low quality, distorted, ugly",
            strength=strength,
            guidance_scale=7.5,
            num_inference_steps=30,
            num_images_per_prompt=1,
            seed=42
        )
        
        if result:
            print("âœ… å›¾ç”Ÿå›¾å®Œæˆ!")
            app.display_images(result, f"Custom: {prompt[:30]}...")
            return result
        else:
            print("âŒ å›¾ç”Ÿå›¾å¤±è´¥")
            return None
            
    except Exception as e:
        print(f"âŒ å›¾ç”Ÿå›¾å‡ºé”™: {e}")
        return None


def batch_img2img(image_path: str, prompts: list, strength: float = 0.7):
    """æ‰¹é‡å›¾ç”Ÿå›¾"""
    print(f"ğŸ¨ æ‰¹é‡å›¾ç”Ÿå›¾: {len(prompts)} ä¸ªå˜æ¢")
    print("=" * 40)
    
    if not os.path.exists(image_path):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return
    
    app = StableDiffusionApp()
    results = []
    
    for i, prompt in enumerate(prompts):
        print(f"\nğŸ­ å˜æ¢ {i+1}/{len(prompts)}: {prompt}")
        
        try:
            result = app.generate_img2img(
                prompt=prompt,
                image=image_path,
                negative_prompt="blurry, low quality, distorted, ugly",
                strength=strength,
                guidance_scale=7.5,
                num_inference_steps=30,
                num_images_per_prompt=1,
                seed=100 + i
            )
            
            if result:
                print(f"âœ… å˜æ¢ {i+1} å®Œæˆ!")
                app.display_images(result, f"Transform {i+1}: {prompt[:20]}...")
                results.append(result)
            else:
                print(f"âŒ å˜æ¢ {i+1} å¤±è´¥")
                
        except Exception as e:
            print(f"âŒ å˜æ¢ {i+1} å‡ºé”™: {e}")
    
    print(f"\nâœ… æ‰¹é‡å˜æ¢å®Œæˆ! æˆåŠŸ: {len(results)}/{len(prompts)}")
    return results


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å›¾ç”Ÿå›¾ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    print("\nè¯·é€‰æ‹©è¦è¿è¡Œçš„ç¤ºä¾‹:")
    print("1. ç®€å•å›¾ç”Ÿå›¾ç¤ºä¾‹")
    print("2. è‡ªå®šä¹‰å›¾ç”Ÿå›¾")
    print("3. æ‰¹é‡å›¾ç”Ÿå›¾")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
        
        if choice == "1":
            simple_img2img_example()
        
        elif choice == "2":
            print("\nğŸ“¸ è‡ªå®šä¹‰å›¾ç”Ÿå›¾")
            image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
            prompt = input("è¯·è¾“å…¥å˜æ¢æç¤ºè¯: ").strip()
            strength = float(input("è¯·è¾“å…¥å˜æ¢å¼ºåº¦ (0.0-1.0, é»˜è®¤0.7): ").strip() or "0.7")
            
            if image_path and prompt:
                custom_img2img(prompt, image_path, strength)
            else:
                print("âŒ è¯·æä¾›å›¾ç‰‡è·¯å¾„å’Œæç¤ºè¯")
        
        elif choice == "3":
            print("\nğŸ¨ æ‰¹é‡å›¾ç”Ÿå›¾")
            image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
            
            if image_path:
                # é¢„è®¾çš„å˜æ¢æç¤ºè¯
                prompts = [
                    "transform into anime style, colorful and vibrant",
                    "make it look like a watercolor painting with soft colors",
                    "add dramatic lighting and cinematic atmosphere",
                    "transform into cyberpunk style with neon lights",
                    "make it look like a vintage photograph with sepia tones"
                ]
                
                print(f"å°†ä½¿ç”¨ä»¥ä¸‹ {len(prompts)} ä¸ªå˜æ¢:")
                for i, prompt in enumerate(prompts, 1):
                    print(f"  {i}. {prompt}")
                
                confirm = input("\nç¡®è®¤å¼€å§‹æ‰¹é‡å˜æ¢? (y/n): ").strip().lower()
                if confirm == 'y':
                    batch_img2img(image_path, prompts, 0.7)
                else:
                    print("âŒ å–æ¶ˆæ‰¹é‡å˜æ¢")
            else:
                print("âŒ è¯·æä¾›å›¾ç‰‡è·¯å¾„")
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
    
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
    
    print("\nâœ… ç¨‹åºç»“æŸ!")


if __name__ == '__main__':
    main()
