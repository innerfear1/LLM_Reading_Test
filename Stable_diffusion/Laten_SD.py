# Stable Diffusion for Mac M-series
# Based on Stability-AI official scripts
# By inner

import os
import torch
import numpy as np
from PIL import Image
from typing import List, Optional, Union
import matplotlib.pyplot as plt

try:
    from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
    from diffusers.utils import logging
except ImportError as e:
    print(f"Import error: {e}")
    print("Trying alternative import...")
    from diffusers import StableDiffusionPipeline
    from diffusers.schedulers import DPMSolverMultistepScheduler
    from diffusers.utils import logging

logger = logging.get_logger(__name__)


class ModelSetting:
    """æ¨¡å‹è®¾ç½®ç±»"""
    
    def __init__(self, model_id: str = "runwayml/stable-diffusion-v1-5"):
        self.model_id = model_id
        self.device = self._get_device()
        self.pipeline = None
        self.setup_pipeline()
    
    def _get_device(self) -> str:
        if torch.backends.mps.is_available():
            return "mps"
        elif torch.cuda.is_available():
            return "cuda"
        else:
            return "cpu"
    
    def setup_pipeline(self):
        try:
            print(f"Loading model {self.model_id} on device {self.device}")
            
            # å¯¹äºMPSè®¾å¤‡ï¼Œä½¿ç”¨float32é¿å…ç²¾åº¦é—®é¢˜
            if self.device == "mps":
                torch_dtype = torch.float32
                print("Using float32 for MPS device to avoid precision issues")
            elif self.device == "cuda":
                torch_dtype = torch.float16
            else:
                torch_dtype = torch.float32
            
            self.pipeline = StableDiffusionPipeline.from_pretrained(
                self.model_id,
                torch_dtype=torch_dtype,
                safety_checker=None,
                requires_safety_checker=False,
                use_safetensors=True
            )
            
            self.pipeline = self.pipeline.to(self.device)
            
            # è®¾ç½®è°ƒåº¦å™¨
            self.pipeline.scheduler = DPMSolverMultistepScheduler.from_config(
                self.pipeline.scheduler.config
            )
            
            # MPSä¼˜åŒ–
            if self.device == "mps":
                self.pipeline.enable_attention_slicing()
                # ç¦ç”¨å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ï¼Œé¿å…MPSé—®é¢˜
                try:
                    self.pipeline.disable_memory_efficient_attention()
                except:
                    pass
            
            print("Pipeline loaded successfully!")
            
        except Exception as e:
            print(f"Failed to load pipeline: {e}")
            raise


class Text2Img:
    """æ–‡ç”Ÿå›¾ç±»"""
    
    def __init__(self, model_setting: ModelSetting):
        self.model_setting = model_setting
        self.pipeline = model_setting.pipeline
    
    def generate(
        self,
        prompt: str,
        negative_prompt: str = "",
        height: int = 512,
        width: int = 512,
        num_inference_steps: int = 20,
        guidance_scale: float = 7.5,
        num_images_per_prompt: int = 1,
        seed: Optional[int] = None,
        output_dir: str = "./outputs"
    ) -> List[Image.Image]:
        
        if seed is not None:
            torch.manual_seed(seed)
        
        os.makedirs(output_dir, exist_ok=True)
        
        try:
            print(f"Generating images for prompt: {prompt}")
            print(f"Device: {self.model_setting.device}")
            print(f"Parameters: steps={num_inference_steps}, guidance={guidance_scale}, size={height}x{width}")
            
            # ç¡®ä¿è¾“å…¥å‚æ•°æ­£ç¡®
            generator = None
            if seed is not None:
                generator = torch.Generator(device=self.model_setting.device).manual_seed(seed)
            
            with torch.no_grad():
                result = self.pipeline(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    height=height,
                    width=width,
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale,
                    num_images_per_prompt=num_images_per_prompt,
                    generator=generator,
                    return_dict=False
                )
            
            images = result[0]
            
            # æ£€æŸ¥ç”Ÿæˆçš„å›¾åƒ
            if images and len(images) > 0:
                first_image = images[0]
                print(f"Generated image shape: {first_image.size}")
                print(f"Generated image mode: {first_image.mode}")
                
                # æ£€æŸ¥å›¾åƒæ˜¯å¦å…¨é»‘
                img_array = np.array(first_image)
                if np.all(img_array == 0):
                    print("âš ï¸ Warning: Generated image appears to be all black!")
                    print("This might be due to model loading or device compatibility issues.")
                else:
                    print(f"âœ… Image generation successful! Mean pixel value: {np.mean(img_array):.2f}")
            
            print(f"Generated {len(images)} images successfully!")
            self._save_images(images, prompt, output_dir)
            return images
            
        except Exception as e:
            print(f"Generation failed: {e}")
            print(f"Error type: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            raise
    
    def _save_images(self, images: List[Image.Image], prompt: str, output_dir: str):
        for i, image in enumerate(images):
            safe_prompt = "".join(c for c in prompt if c.isalnum() or c in (' ', '-', '_')).rstrip()
            safe_prompt = safe_prompt[:50]
            
            filename = f"{safe_prompt}_{i+1}.png"
            filepath = os.path.join(output_dir, filename)
            image.save(filepath)
            print(f"Saved: {filepath}")


class Img2Img:
    """å›¾ç”Ÿå›¾ç±»"""
    def __init__(self, model_setting: ModelSetting):
        self.model_setting = model_setting
        self.pipeline = model_setting.pipeline
    
    def generate(
        self,
        prompt: str,
        image: Union[str, Image.Image],
        negative_prompt: str = "",
        strength: float = 0.8,
        guidance_scale: float = 7.5,
        num_inference_steps: int = 20,
        num_images_per_prompt: int = 1,
        seed: Optional[int] = None,
        output_dir: str = "./outputs"
    ) -> List[Image.Image]:
        
        if seed is not None:
            torch.manual_seed(seed)
        
        os.makedirs(output_dir, exist_ok=True)
        
        if isinstance(image, str):
            input_image = Image.open(image).convert("RGB")
        else:
            input_image = image
        
        try:
            print(f"Generating images for prompt: {prompt}")
            
            images = self.pipeline(
                prompt=prompt,
                negative_prompt=negative_prompt,
                image=input_image,
                strength=strength,
                guidance_scale=guidance_scale,
                num_inference_steps=num_inference_steps,
                num_images_per_prompt=num_images_per_prompt,
                return_dict=False
            )[0]
            
            print(f"Generated {len(images)} images successfully!")
            self._save_images(images, prompt, output_dir)
            return images
            
        except Exception as e:
            print(f"Generation failed: {e}")
            raise
    
    def _save_images(self, images: List[Image.Image], prompt: str, output_dir: str):
        for i, image in enumerate(images):
            safe_prompt = "".join(c for c in prompt if c.isalnum() or c in (' ', '-', '_')).rstrip()
            safe_prompt = safe_prompt[:50]
            
            filename = f"img2img_{safe_prompt}_{i+1}.png"
            filepath = os.path.join(output_dir, filename)
            image.save(filepath)
            print(f"Saved: {filepath}")


class StableDiffusionApp:
    """Stable Diffusionåº”ç”¨ä¸»ç±»"""
    
    def __init__(self, model_id: str = "runwayml/stable-diffusion-v1-5"):
        self.model_setting = ModelSetting(model_id)
        self.text2img = Text2Img(self.model_setting)
        self.img2img = Img2Img(self.model_setting)
    
    def generate_text2img(
        self,
        prompt: str,
        negative_prompt: str = "",
        height: int = 512,
        width: int = 512,
        num_inference_steps: int = 20,
        guidance_scale: float = 7.5,
        num_images_per_prompt: int = 1,
        seed: Optional[int] = None
    ) -> List[Image.Image]:
        return self.text2img.generate(
            prompt=prompt,
            negative_prompt=negative_prompt,
            height=height,
            width=width,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            num_images_per_prompt=num_images_per_prompt,
            seed=seed
        )
    
    def generate_img2img(
        self,
        prompt: str,
        image: Union[str, Image.Image],
        negative_prompt: str = "",
        strength: float = 0.8,
        guidance_scale: float = 7.5,
        num_inference_steps: int = 20,
        num_images_per_prompt: int = 1,
        seed: Optional[int] = None
    ) -> List[Image.Image]:
        return self.img2img.generate(
            prompt=prompt,
            image=image,
            negative_prompt=negative_prompt,
            strength=strength,
            guidance_scale=guidance_scale,
            num_inference_steps=num_inference_steps,
            num_images_per_prompt=num_images_per_prompt,
            seed=seed
        )
    
    def display_images(self, images: List[Image.Image], title: str = "Generated Images"):
        if not images:
            return
        
        n_images = len(images)
        cols = min(n_images, 3)
        rows = (n_images + cols - 1) // cols
        
        fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))
        
        if n_images == 1:
            axes = [axes]
        elif rows == 1:
            axes = axes.reshape(1, -1)
        
        axes_array = np.array(axes).reshape(-1)
        
        for i, image in enumerate(images):
            ax = axes_array[i]
            ax.imshow(image)
            ax.set_title(f"Image {i+1}")
            ax.axis('off')
        
        for j in range(len(images), len(axes_array)):
            axes_array[j].axis('off')
        
        plt.suptitle(title, fontsize=16)
        plt.tight_layout()
        plt.show()


def test_simple_generation():
    """ç®€å•æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª Testing simple image generation...")
    
    try:
        app = StableDiffusionApp()
        
        # ä½¿ç”¨ç®€å•çš„æç¤ºè¯æµ‹è¯•
        prompt = "a red apple on a white table"
        
        print(f"Testing with prompt: {prompt}")
        
        images = app.generate_text2img(
            prompt=prompt,
            negative_prompt="blurry, low quality",
            num_inference_steps=10,  # å‡å°‘æ­¥æ•°åŠ å¿«æµ‹è¯•
            guidance_scale=7.5,
            num_images_per_prompt=1,
            seed=42
        )
        
        if images:
            print("âœ… Test generation successful!")
            app.display_images(images, "Test Image")
            return True
        else:
            print("âŒ No images generated")
            return False
            
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        return False


def demo_img2img():
    """å›¾ç”Ÿå›¾æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ¨ Image-to-Image Generation Demo")
    print("=" * 50)
    
    try:
        app = StableDiffusionApp()
        
        # é¦–å…ˆç”Ÿæˆä¸€å¼ åŸºç¡€å›¾ç‰‡ä½œä¸ºè¾“å…¥
        print("ğŸ“¸ Step 1: Generating base image...")
        base_images = app.generate_text2img(
            prompt="a simple portrait of a person, neutral expression, clean background",
            negative_prompt="blurry, low quality, distorted",
            num_inference_steps=20,
            guidance_scale=7.5,
            num_images_per_prompt=1,
            seed=123
        )
        
        if not base_images:
            print("âŒ Failed to generate base image")
            return
        
        base_image = base_images[0]
        print("âœ… Base image generated successfully!")
        
        # ä¿å­˜åŸºç¡€å›¾ç‰‡
        base_image.save("./outputs/base_image.png")
        print("ğŸ’¾ Base image saved as './outputs/base_image.png'")
        
        # å›¾ç”Ÿå›¾ç¤ºä¾‹
        img2img_examples = [
            {
                "prompt": "transform into a cyberpunk style character with neon lights and futuristic elements",
                "strength": 0.7,
                "description": "Cyberpunk transformation"
            },
            {
                "prompt": "make it look like a vintage oil painting with classical art style",
                "strength": 0.8,
                "description": "Classical painting style"
            },
            {
                "prompt": "add fantasy elements, magical aura, and mystical background",
                "strength": 0.6,
                "description": "Fantasy transformation"
            }
        ]
        
        for i, example in enumerate(img2img_examples):
            print(f"\nğŸ­ Step {i+2}: {example['description']}")
            print(f"Prompt: {example['prompt']}")
            print(f"Strength: {example['strength']}")
            
            try:
                result_images = app.generate_img2img(
                    prompt=example['prompt'],
                    image=base_image,  # ä½¿ç”¨ç”Ÿæˆçš„åŸºç¡€å›¾ç‰‡
                    negative_prompt="blurry, low quality, distorted, ugly",
                    strength=example['strength'],
                    guidance_scale=7.5,
                    num_inference_steps=30,
                    num_images_per_prompt=1,
                    seed=456 + i
                )
                
                if result_images:
                    print(f"âœ… {example['description']} completed!")
                    app.display_images(result_images, f"Img2Img - {example['description']}")
                else:
                    print(f"âŒ {example['description']} failed")
                    
            except Exception as e:
                print(f"âŒ {example['description']} failed: {e}")
        
        print("\nâœ… Image-to-Image demo completed!")
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()


def demo_img2img_with_existing_image(image_path: str):
    """ä½¿ç”¨ç°æœ‰å›¾ç‰‡è¿›è¡Œå›¾ç”Ÿå›¾æ¼”ç¤º"""
    print(f"ğŸ¨ Image-to-Image with existing image: {image_path}")
    print("=" * 50)
    
    try:
        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            print(f"âŒ Image file not found: {image_path}")
            return
        
        app = StableDiffusionApp()
        
        # åŠ è½½ç°æœ‰å›¾ç‰‡
        input_image = Image.open(image_path).convert("RGB")
        print(f"ğŸ“¸ Loaded image: {input_image.size}")
        
        # å›¾ç”Ÿå›¾å˜æ¢ç¤ºä¾‹
        transformations = [
            {
                "prompt": "transform into anime style, colorful and vibrant",
                "strength": 0.7,
                "description": "Anime style"
            },
            {
                "prompt": "make it look like a watercolor painting with soft colors",
                "strength": 0.8,
                "description": "Watercolor style"
            },
            {
                "prompt": "add dramatic lighting and cinematic atmosphere",
                "strength": 0.5,
                "description": "Cinematic style"
            }
        ]
        
        for i, transform in enumerate(transformations):
            print(f"\nğŸ­ Transformation {i+1}: {transform['description']}")
            print(f"Prompt: {transform['prompt']}")
            
            try:
                result_images = app.generate_img2img(
                    prompt=transform['prompt'],
                    image=input_image,
                    negative_prompt="blurry, low quality, distorted",
                    strength=transform['strength'],
                    guidance_scale=7.5,
                    num_inference_steps=30,
                    num_images_per_prompt=1,
                    seed=789 + i
                )
                
                if result_images:
                    print(f"âœ… {transform['description']} completed!")
                    app.display_images(result_images, f"Transform - {transform['description']}")
                else:
                    print(f"âŒ {transform['description']} failed")
                    
            except Exception as e:
                print(f"âŒ {transform['description']} failed: {e}")
        
        print("\nâœ… Image transformation demo completed!")
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°æ¼”ç¤º"""
    print("ğŸš€ Stable Diffusion for Mac M-series")
    print("=" * 50)
    
    # æ˜¾ç¤ºé€‰é¡¹èœå•
    print("\nè¯·é€‰æ‹©è¦è¿è¡Œçš„åŠŸèƒ½:")
    print("1. æ–‡ç”Ÿå›¾ (Text-to-Image)")
    print("2. å›¾ç”Ÿå›¾æ¼”ç¤º (Image-to-Image Demo)")
    print("3. ä½¿ç”¨ç°æœ‰å›¾ç‰‡è¿›è¡Œå›¾ç”Ÿå›¾")
    print("4. è¿è¡Œå®Œæ•´æ¼”ç¤º")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
        
        if choice == "1":
            print("\nğŸ¨ æ–‡ç”Ÿå›¾æ¼”ç¤º")
            print("=" * 30)
            app = StableDiffusionApp()
            
            prompts = [
                "An impressionist oil painting of a girl in a white dress running through a golden wheat field. The sky is bright blue, with loose, energetic brushstrokes. Vibrant colors and strong light contrast convey a lively atmosphere.",
                "A young woman in a vintage white dress standing under cherry blossoms, smiling at the camera. The background is filled with pale pink flowers. Soft morning light. Photorealistic style, high resolution."
            ]
            
            for i, prompt in enumerate(prompts):
                print(f"\nğŸ¨ Generating image {i+1}/{len(prompts)}...")
                print(f"Prompt: {prompt}")
                
                try:
                    images = app.generate_text2img(
                        prompt=prompt,
                        negative_prompt="blurry, low quality, distorted",
                        num_inference_steps=40,
                        guidance_scale=7.5,
                        num_images_per_prompt=1,
                        seed=42 + i
                    )
                    
                    app.display_images(images, f"Text2Img - {prompt[:30]}...")
                    
                except Exception as e:
                    print(f"âŒ Generation failed: {e}")
        
        elif choice == "2":
            print("\nğŸ­ å›¾ç”Ÿå›¾æ¼”ç¤º")
            demo_img2img()
        
        elif choice == "3":
            print("\nğŸ“¸ ä½¿ç”¨ç°æœ‰å›¾ç‰‡è¿›è¡Œå›¾ç”Ÿå›¾")
            image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
            if image_path:
                demo_img2img_with_existing_image(image_path)
            else:
                print("âŒ æœªæä¾›å›¾ç‰‡è·¯å¾„")
        
        elif choice == "4":
            print("\nğŸ¨ è¿è¡Œå®Œæ•´æ¼”ç¤º")
            print("=" * 30)
            
            # æ–‡ç”Ÿå›¾éƒ¨åˆ†
            app = StableDiffusionApp()
            prompts = [
                "An impressionist oil painting of a girl in a white dress running through a golden wheat field. The sky is bright blue, with loose, energetic brushstrokes. Vibrant colors and strong light contrast convey a lively atmosphere.",
                "A young woman in a vintage white dress standing under cherry blossoms, smiling at the camera. The background is filled with pale pink flowers. Soft morning light. Photorealistic style, high resolution."
            ]
            
            for i, prompt in enumerate(prompts):
                print(f"\nğŸ¨ Generating image {i+1}/{len(prompts)}...")
                print(f"Prompt: {prompt}")
                
                try:
                    images = app.generate_text2img(
                        prompt=prompt,
                        negative_prompt="blurry, low quality, distorted",
                        num_inference_steps=40,
                        guidance_scale=7.5,
                        num_images_per_prompt=1,
                        seed=42 + i
                    )
                    
                    app.display_images(images, f"Text2Img - {prompt[:30]}...")
                    
                except Exception as e:
                    print(f"âŒ Generation failed: {e}")
            
            # å›¾ç”Ÿå›¾éƒ¨åˆ†
            print("\n" + "=" * 50)
            demo_img2img()
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¿è¡Œç¨‹åºé‡æ–°é€‰æ‹©")
    
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
    
    print("\nâœ… ç¨‹åºç»“æŸ!")


if __name__ == '__main__':
    main()