{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 浜瑙ｅ寮\n",
    "![self-attention寮](./pics/self-attention.png)\n",
    "\n",
    "### 2. 浠ｇ瀹\n",
    "### 路 SelfAttentionV1 寮瀹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5010, -1.4322, -0.2414,  0.1632],\n",
       "         [ 0.5117, -1.5739, -0.2755,  0.1640]],\n",
       "\n",
       "        [[-0.4387,  0.4075, -0.5785,  0.1173],\n",
       "         [-0.4382,  0.4043, -0.5777,  0.1205]],\n",
       "\n",
       "        [[ 0.5927, -0.7009, -0.0076, -0.5356],\n",
       "         [ 0.6485, -0.7573,  0.0375, -0.7019]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Self_AttentionV1(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 728) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.query_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, hidden_dim]\n",
    "        Q = self.query_proj(x)\n",
    "        K = self.key_proj(x)\n",
    "        V = self.value_proj(x)\n",
    "\n",
    "        # Q, K, V shape: [batch_size, seq_len, hidden_dim]\n",
    "        # compute attention scores \n",
    "        # attebtion_value shape: [batch_size, seq_len, seq_len]\n",
    "        attention_value = torch.matmul(\n",
    "            # K reshape: [batch_size, seq_len, hidden_dim] -> [batch_size, hidden_dim, seq_len]\n",
    "            Q, K.transpose(-1, -2)\n",
    "        )\n",
    "\n",
    "        # compute attention weights\n",
    "        # attention_weights shape: [batch_size, seq_len, seq_len]\n",
    "        attention_weight = torch.softmax(\n",
    "            attention_value / math.sqrt(self.hidden_dim),\n",
    "            dim = -1\n",
    "        )\n",
    "\n",
    "        # compute attention output\n",
    "        # attention_output shape: [batch_size, seq_len, hidden_dim]\n",
    "        output = torch.matmul(\n",
    "            attention_weight, V\n",
    "        )\n",
    "\n",
    "        return output\n",
    "\n",
    "x = torch.randn(3 ,2, 4)\n",
    "\n",
    "self_att_net = Self_AttentionV1(4)\n",
    "\n",
    "self_att_net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 路 Self-AttentionV2 浼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2136,  0.2236,  0.6926,  0.2348],\n",
       "         [-0.1595,  0.1828,  0.6793,  0.1907]],\n",
       "\n",
       "        [[-0.3588,  0.5055, -0.2845,  0.2861],\n",
       "         [-0.3767,  0.5226, -0.2824,  0.3109]],\n",
       "\n",
       "        [[-0.8789,  0.5472, -0.4421, -0.5628],\n",
       "         [-0.9618,  0.2683,  0.0440, -0.0110]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Self_AttentionV2(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        self.proj = nn.Linear(dim, dim * 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape : (batch_size, seq_len, dim)\n",
    "        # QKV shape : (batch_size, seq_len, dim * 3)\n",
    "        QKV = self.proj(x)\n",
    "        Q, K, V = torch.split(QKV, self.dim, dim = -1)\n",
    "        att_weight = torch.softmax(\n",
    "            torch.matmul(\n",
    "                Q, K.transpose(-2, -1)\n",
    "            ) / math.sqrt(self.dim), dim = -1\n",
    "        )\n",
    "\n",
    "        # @ == torch.matmul\n",
    "        output = att_weight @ V\n",
    "        return output\n",
    "        \n",
    "x = torch.randn(3 ,2, 4)\n",
    "self_att_netV2 = Self_AttentionV2(4)\n",
    "self_att_netV2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 路 Self-AttentionV3 缁\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "repeat mask shape:  torch.Size([3, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3208, -0.6199],\n",
       "         [-0.6620, -0.5617],\n",
       "         [-0.5866, -0.5632],\n",
       "         [-0.6273, -0.5385]],\n",
       "\n",
       "        [[-1.2397, -1.0820],\n",
       "         [-1.1849, -1.0373],\n",
       "         [-1.1710, -1.0259],\n",
       "         [-0.3342, -0.6982]],\n",
       "\n",
       "        [[-1.0509, -0.7904],\n",
       "         [-1.0509, -0.7904],\n",
       "         [-1.0509, -0.7904],\n",
       "         [-1.0509, -0.7904]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.dropout position\n",
    "# 2.attention mask\n",
    "# 3.output ╅垫灏\n",
    "\n",
    "class Self_AttentionV3(nn.Module):\n",
    "    def __init__(self, dim, Dropout_rate = 0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        self.proj = nn.Linear(dim, dim * 3)\n",
    "        self.attention_dropout = nn.Dropout(Dropout_rate)\n",
    "\n",
    "        self.output_proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x, attention_mask = None):\n",
    "        QKV = self.proj(x)\n",
    "        # x shape: [B, seq, D]\n",
    "        Q, K, V = torch.split(QKV, self.dim, dim = -1)\n",
    "\n",
    "        # attention_weight shape: [B, seq, seq]\n",
    "        attention_weight = Q @ K.transpose(-1, -2) / math.sqrt(self.dim)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attention_weight = attention_weight.masked_fill(\n",
    "                attention_mask == 0, \n",
    "                float(\"-1e20\")\n",
    "            )\n",
    "        \n",
    "        attention_weight = torch.softmax(\n",
    "            attention_weight,\n",
    "            dim = -1\n",
    "        )\n",
    "\n",
    "        # dropout the attention weight\n",
    "        attention_weight = self.attention_dropout(attention_weight)\n",
    "        attention_result = attention_weight @ V\n",
    "\n",
    "        # output \n",
    "        output = self.output_proj(attention_result)\n",
    "        return output\n",
    "\n",
    "x = torch.randn(3 ,4, 2)\n",
    "# mask shape: [B, seq]\n",
    "mask = torch.tensor(\n",
    "    [\n",
    "        [1, 1, 1, 0],\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 0, 0, 0]\n",
    "    ]\n",
    ")\n",
    "print(mask.shape)\n",
    "# mask shape: [B, seq, seq]\n",
    "mask = mask.unsqueeze(dim = 1).repeat(1, 4, 1)\n",
    "print(\"repeat mask shape: \", mask.size())\n",
    "\n",
    "self_att_netV3 = Self_AttentionV3(2)\n",
    "self_att_netV3(x, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 路 Self-Attention interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3428, 0.3319, 0.3253, 0.0000],\n",
      "         [0.3513, 0.3294, 0.3193, 0.0000],\n",
      "         [0.3465, 0.3309, 0.3226, 0.0000],\n",
      "         [0.3500, 0.3297, 0.3203, 0.0000]],\n",
      "\n",
      "        [[0.5091, 0.4909, 0.0000, 0.0000],\n",
      "         [0.5079, 0.4921, 0.0000, 0.0000],\n",
      "         [0.5110, 0.4890, 0.0000, 0.0000],\n",
      "         [0.5091, 0.4909, 0.0000, 0.0000]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0035,  0.2287],\n",
       "         [ 0.0671,  0.3224],\n",
       "         [ 0.1035,  0.4267],\n",
       "         [ 0.1388,  0.3070]],\n",
       "\n",
       "        [[-0.0160,  0.2526],\n",
       "         [ 0.0379,  0.4628],\n",
       "         [ 0.0374,  0.4630],\n",
       "         [ 0.0377,  0.4629]],\n",
       "\n",
       "        [[ 0.0437,  0.4510],\n",
       "         [ 0.0437,  0.4510],\n",
       "         [ 0.0437,  0.4510],\n",
       "         [ 0.0437,  0.4510]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Self_AttentionV4(nn.Module):\n",
    "    def __init__(self, dim, dropout_rate = 0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        self.Q = nn.Linear(dim, dim)\n",
    "        self.K = nn.Linear(dim, dim)\n",
    "        self.V = nn.Linear(dim, dim)\n",
    "\n",
    "        self.attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, atten_mask = None):\n",
    "        # [b,s,d]\n",
    "        Q = self.Q(x)\n",
    "        K = self.K(x)\n",
    "        V = self.V(x)\n",
    "\n",
    "        attention_weight = Q @ K.transpose(-1, -2) / math.sqrt(self.dim)\n",
    "        if atten_mask is not None:\n",
    "            attention_weight = attention_weight.masked_fill(\n",
    "                atten_mask == 0,\n",
    "                float(\"-inf\")\n",
    "            )\n",
    "        \n",
    "        attention_weight = torch.softmax(\n",
    "            attention_weight,\n",
    "            dim = -1\n",
    "        )\n",
    "        \n",
    "        attention_weight = self.attention_dropout(attention_weight)\n",
    "\n",
    "        output = attention_weight @ V\n",
    "\n",
    "        return output\n",
    "\n",
    "x = torch.rand(3, 4, 2)\n",
    "\n",
    "mask = torch.tensor(\n",
    "    [\n",
    "        [1, 1, 1, 0],\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 0, 0, 0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "repeat_mask = mask.unsqueeze(dim = 1).repeat(1, 4, 1)\n",
    "\n",
    "net = Self_AttentionV4(2)\n",
    "net(x, repeat_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
