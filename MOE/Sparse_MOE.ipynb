{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse-MOE\n",
    "![sparse-moe](./pics/Sparse_MoE.png)\n",
    "和Basic-MOE的区别是，在Sparse-MOE中，MOE选择TopK个专家，然后对这topK个专家的输出进行加权求和。\n",
    "并把输入样本变成了大模型中真实的输入Shape，（batch_size, sqe_len, hidden_dim）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T04:00:19.414707Z",
     "start_time": "2025-06-13T04:00:15.345345Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T04:01:09.572794Z",
     "start_time": "2025-06-13T04:01:09.550795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BasicExpert(nn.Module):\n",
    "    # 一个 Expert 可以是一个最简单的， linear 层即可\n",
    "    # 也可以是 MLP 层\n",
    "    # 也可以是 更复杂的 MLP 层（active function 设置为 swiglu）\n",
    "    def __init__(self, feature_in, feature_out):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_in, feature_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T04:02:00.876208Z",
     "start_time": "2025-06-13T04:02:00.848215Z"
    }
   },
   "source": [
    "class MOERouter(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.gate=nn.Linear(config.hidden_dim,config.expert_number)\n",
    "        #但是后面只会选top_k个专家\n",
    "        self.exper_number=config.expert_number\n",
    "        self.top_k=config.top_k\n",
    "\n",
    "    def forward(self,x):\n",
    "        #假设expert number是8，top_k是2\n",
    "        router_logits=self.gate(x) #(batch*seq_len,exper_number)\n",
    "        #计算每一个专家的概率\n",
    "        router_probs=F.softmax(router_logits,dim=1,dtype=torch.float)\n",
    "        #计算top_k专家的输出，top_k可反向传播\n",
    "        router_weights,selected_expers_inices=torch.topk(\n",
    "            router_probs,self.top_k,dim=-1\n",
    "        )#shape都是（batch*seq_len,top_k）\n",
    "\n",
    "\n",
    "        #专家权重归一化\n",
    "        router_weights=router_weights/router_weights.sum(\n",
    "            dim=-1,\n",
    "            keepdim=True\n",
    "        )\n",
    "        router_weights=router_weights.to(x.dtype)\n",
    "\n",
    "        #生成专家掩码\n",
    "        expert_mask=F.one_hot(\n",
    "            selected_expers_inices,\n",
    "            num_classes=self.exper_number\n",
    "        )\n",
    "        #(batch*seq_len,top_k,exper_number)\n",
    "\n",
    "        expert_mask=expert_mask.permute(2,1,0)\n",
    "        #(exper_number,top_k,batch*seq_len)\n",
    "        return router_logits,router_weights,selected_expers_inices,expert_mask\n",
    "        #router_logits(batch*seq_len,expert_number)\n",
    "        #router_weights(batch*seq_len,top_k)\n",
    "        #selected_experts_indices(batch*seq_len,top_k)\n",
    "        #expert_mask(exper_number,top_k,batch*seq_len)\n",
    "\n",
    "\n",
    "class MOEConfig:\n",
    "    def __init__(self,hidden_dim,expert_number,top_k,shared_experts_number=2):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.expert_number = expert_number\n",
    "        self.top_k = top_k\n",
    "        self.shared_experts_number = shared_experts_number\n",
    "\n",
    "\n",
    "\n",
    "class SparseMOE(nn.Module):\n",
    "     #稀疏 MOE 模型，这里每一个 token 都会过 topk 个专家，得到对应token 的 hidden_embeddings\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.hidden_dim=config.hidden_dim\n",
    "        self.expert_number=config.expert_number\n",
    "\n",
    "        self.top_k=config.top_k\n",
    "\n",
    "        #初始化专家\n",
    "        self.experts=nn.ModuleList(\n",
    "            [\n",
    "                BasicExpert(self.hidden_dim,self.hidden_dim,) for _ in range(self.expert_number)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.router=MOERouter(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x shape (batch,seq_len,hidden_dim)\n",
    "        batch_size,seq_len,hidden_dim=x.size()\n",
    "\n",
    "        #token维度计算，x,reshape(batch*seq_len,hidden_dim)\n",
    "        hidden_states=x.view(-1,hidden_dim)\n",
    "        #做相关专家计算\n",
    "        router_logits,router_weights,selected_experts_indices,expert_mask=self.router(hidden_states)\n",
    "        #expert_mask shape(exper_number,top_k,batch*seq_len)\n",
    "        #最终是（batch*seq_len,hidden_dim）\n",
    "        final_hidden_states=torch.zeros(\n",
    "            (batch_size*seq_len,hidden_dim),\n",
    "            dtype=hidden_states.dtype,\n",
    "            device=hidden_states.device\n",
    "        )\n",
    "        #遍历每个专家模型\n",
    "        #把选中的专家的token的hidden_states加到final_hidden_states中\n",
    "        #expert=0可能有100个token选中\n",
    "        #token的总数是batch*seq_len\n",
    "        for expert_idx in range(self.expert_number):\n",
    "            expert_layer=self.experts[expert_idx]\n",
    "            #expert_masks(expert_number,top_k,batch*seq_len)\n",
    "            current_expert_mask=expert_mask[expert_idx]\n",
    "            #current_expert_mask shape(top_k,batch*seq_len)\n",
    "\n",
    "            router_weights_idx,top_x=torch.where(current_expert_mask)\n",
    "            #idx是0或1  #假设top_k是2\n",
    "            #表示这个token是作为当前专家的top1还是top2\n",
    "            #top_x是token在batch*seq_len中的位置索引\n",
    "            #例如对于batch_size=2,seq_len=4的输入：\n",
    "            #top_x的值的范围是0-7，表示在展平台后的8个token中的位置\n",
    "            #他们都是一个一维的值\n",
    "            #idx肯定是用来选weight,top_x用来选取hidden_states\n",
    "\n",
    "            #hidden_states#shape是（1，batch*seq_len,hidden_dim）\n",
    "            current_state=hidden_states.unsqueeze(0)[:,top_x,:].reshape(-1,hidden_dim)\n",
    "            #current_state shape(selected_token_number,hidden_dim)\n",
    "            current_state=expert_layer(current_state)\n",
    "            #100个token选中\n",
    "            #router_weights shape是（batch*seq_len,top_k）\n",
    "            current_token_router_weight=router_weights[top_x,router_weights_idx]\n",
    "            #最终的shape就变成了(selected_token_number)\n",
    "            current_token_router_weight=current_token_router_weight.unsqueeze(-1)\n",
    "            #最终的current=token_router_weight shape就变成了（selected_token_number,1）\n",
    "\n",
    "            current_hidden_states=current_state*current_token_router_weight\n",
    "            final_hidden_states.index_add_(\n",
    "                0,\n",
    "                top_x,\n",
    "                current_hidden_states.to(hidden_states.dtype)\n",
    "            )\n",
    "            #把final_hidden_states还原到原来的shape\n",
    "            final_hidden_states=final_hidden_states.reshape(batch_size,seq_len,hidden_dim)\n",
    "            return final_hidden_states,router_logits\n",
    "            #shape是（b*s,expert_number）\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T04:02:18.963042Z",
     "start_time": "2025-06-13T04:02:18.789071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_token_level_moe():\n",
    "    x=torch.rand(2,4,16)\n",
    "    config=MOEConfig(16,2,2)\n",
    "    token_level_moe=SparseMOE(config)\n",
    "    out=token_level_moe(x)\n",
    "    print(out[0].shape,out[1].shape)\n",
    "\n",
    "test_token_level_moe()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 16]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
