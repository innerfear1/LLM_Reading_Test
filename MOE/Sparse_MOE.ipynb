{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse-MOE\n",
    "![sparse-moe](./pics/Sparse_MoE.png)\n",
    "和Basic-MOE的区别是，在Sparse-MOE中，MOE选择TopK个专家，然后对这topK个专家的输出进行加权求和。\n",
    "并把输入样本变成了大模型中真实的输入Shape，（batch_size, sqe_len, hidden_dim）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOEConfig:\n",
    "    def __init__(self, hidden_dim, expert_number, top_k, shared_expert_numbers = 2):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.expert_number = expert_number\n",
    "        self.top_k = top_k\n",
    "        self.shared_expert_numbers = shared_expert_numbers\n",
    "\n",
    "\n",
    "class MOERouter(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gate = nn.Linear(config.hidden_dim, config.expert_number)\n",
    "\n",
    "        self.expert_number = config.expert_number\n",
    "        self.top_k = config.top_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        router_logits = self.gate(x)\n",
    "\n",
    "        router_probs = F.softmax(router_logits, dim = 1, dtype = torch.float)\n",
    "        \n",
    "        # top_k 可以反向传播\n",
    "        router_weights, selected_expert_indices = torch.top_k(\n",
    "            router_probs,\n",
    "            self.top_k,\n",
    "            dim = -1\n",
    "        )\n",
    "\n",
    "        router_weights = router_weights / router_weights.sum(\n",
    "            dim = -1,\n",
    "            keepdim = True\n",
    "        )\n",
    "        router_weights = router_weights.to(x.dtype)\n",
    "\n",
    "        expert_mask = F.one_hot(\n",
    "            selected_expert_indices,\n",
    "            num_classes = self.expert_number\n",
    "        ) # (batch, top_k, expert_number)\n",
    "\n",
    "        expert_mask = expert_mask.permute(2, 1, 0)\n",
    "\n",
    "        return router_logits, router_weights, selected_expert_indices, expert_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Spare_MOE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.top_k = config.top_k\n",
    "        self.expert_number = config.expert_number\n",
    "\n",
    "        self.experts = nn.ModuleList(\n",
    "            [\n",
    "                Basic_Expert(\n",
    "                    config.hidden_dim, \n",
    "                    config.hidden_dim\n",
    "                ) for _ in range(config.expert_number)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.shared_experts = nn.ModuleList()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq_len, hidden_dim]\n",
    "        batch_size, seq_len, hidden_dim = x.size()\n",
    "\n",
    "        # token 维度计算\n",
    "        # x reshape to [batch * seq_len, hidden_dim]\n",
    "        hidden_state = x.view(-1, hidden_dim)\n",
    "\n",
    "        # 专家计算\n",
    "        router_logits, router_weights, selected_expert_indices, expert_mask = self.router(hidden_state)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
